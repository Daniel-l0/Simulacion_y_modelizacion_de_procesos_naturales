[MÚSICA] Bienvenidos de nuevo a la segunda semana del curso sobre simulación y modelación de procesos naturales. El objetivo de este tercer módulo es introducir, uno de los conceptos centrales utilizados en la computación de alto rendimiento, que es el paralelismo. ¿Cuál es la idea principal detrás del paralelismo? Así que cuando usted está tratando de resolver un problema en un ordenador, usted puede pensar que puede simplemente dividir el trabajo, así que corte su proceso en dos y hágalo, ejecútelo en dos procesos diferentes y espere tener una ganancia proporcional en el número de procesos que va a resolver simultáneamente. Así que, ¿cómo funciona esto? ¿Cuáles son las arquitecturas que existen para hacer eso? En primer lugar, usted tiene arquitecturas de memoria compartida. Así que tiene muchos bloques de construcción básicos. Así que un bloque de construcción para un ordenador es una CPU, y memoria y un dispositivo de E/S, o entrada salida. Así que la memoria compartida toma muchas de las CPUs y las conecta a una única memoria. Así que cada CPU puede leer directamente en la memoria utilizada por cualquier otra CPU y estas normalmente están programadas con el lenguaje de programación que se llama OpenMP. Y tiene arquitecturas de memoria distribuida donde tiene todos sus ordenadores con su propia memoria y dispositivos de E/S que están conectados entre sí a través de una red. Así que la única forma de que una CPU lea la memoria de otra CPU es que se comuniquen los valores almacenados en la memoria a través de la red. ¿Cuál es el rendimiento de este tipo de arquitecturas? Pues si comparamos el rendimiento de un procesador moderno que normalmente se mide en flops, que significa operación de enlace flotante por segundo, por lo que básicamente mide cuántas operaciones con números reales puede realizar en un segundo. Tenemos que el rendimiento de un procesador moderno es de unos 100 gigaflops. Esto significa unos 100.000 millones de operaciones por segundo. En los superordenadores más rápidos, a partir del 4 de enero de 2015, el superordenador más rápido funciona a unos 52 petaflops, por lo que es el rendimiento teórico lo que significa unos 52 billones de billones de flops. Así que es unas mil millones de veces más rápido que un procesador moderno. Hay complicaciones de extracto de por supuesto cuando estamos tratando de paralelizar un programa. Lo primero es que el concepto en sí mismo es complejo. Cómo dividir un problema en muchas subpartes que sean tan independientes como sea posible es una tarea complicada. Por supuesto, hay problemas en los que simplemente no podemos hacerlo. Aquí les pongo el ejemplo de la serie de Fibonacci, que es tan dependiente cuando calculamos el número relacionado con el índice I a los índices precedentes que la paralelización será posible pero completamente ineficiente. Con esto, terminamos el módulo sobre conceptos de paralelismo. Y a continuación, vamos a hablar de Palabos, que es un solucionador paralelo de Boltzmann en celosía. Gracias por su atención. [MÚSICA]